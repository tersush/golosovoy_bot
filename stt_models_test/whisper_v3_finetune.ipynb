{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0b46bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è≥ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Whisper Large V3 Russian...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74adc1bc1fac4cf6b1e0ed778d546de1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e536bd343baf47abad36e1b710aee2a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6420308d07234398a938c1a636a8dae8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f297b2c889ec438fb41a4f23489c0208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3838f7a7df1d4551b22e6339cd0da3a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aab21989e0a4c39a65b5de4203fe1d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a5ebc170f24a26a1bab4f50b166fbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882986154cfc4af5bbb30cb94dd7329d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Device set to use cpu\n",
      "Using `chunk_length_s` is very experimental with seq2seq models. The results will not necessarily be entirely accurate and will have caveats. More information: https://github.com/huggingface/transformers/pull/20104. Ignore this warning with pipeline(..., ignore_warning=True). To use Whisper for long-form transcription, use rather the model's `generate` method directly as the model relies on it's own chunking mechanism (cf. Whisper original paper, section 3.8. Long-form Transcription).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéß –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª: /home/ppwwrr/project_25/voices/voice-2.wav...\n",
      "\n",
      "‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:\n",
      "\n",
      " —á—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑ —è —Å–º–æ—Ç—Ä–µ–ª–∞ –∫–æ—Ä–æ—á–µ —É –º–µ–Ω—è –≤–æ—Ç —ç—Ç–∏ –¥—É—Ö–∏ –ø–æ—è–≤–∏–ª–∏—Å—å —á—Ç–æ–±—ã –Ω–µ —Å–æ–≤—Ä–∞—Ç—å –¥–µ—Å—è—Ç–æ–º –∏–ª–∏ –≤ –æ–¥–∏–Ω–Ω–∞–¥—Ü–∞—Ç–æ–º –∫–ª–∞—Å—Å–µ –≤–æ—Ç —Ç–∏–ø–∞ –≤–æ—Ç –ª–∏–±–æ –∫–æ–Ω–µ—Ü –¥–µ—Å—è—Ç–∞—è –ª–∏–±–æ –Ω–∞—á–∞–ª–æ –æ–¥–∏–Ω–Ω–∞–¥—Ü–∞—Ç–æ–≥–æ –Ω—É –∫–æ—Ä–æ—á–µ –≤–æ—Ç –æ–Ω–∏ —É –º–µ–Ω—è –ø–æ—è–≤–∏–ª–∏—Å—å –º–Ω–µ –º–∞–º–∞ –∑–∞–∫–∞–∑–∞–ª–∞ –ø–æ—Ç–æ–º—É —á—Ç–æ —ç—Ç–æ –¥—É—Ö–∏ –ø–æ–ª–∏–Ω–æ–≥–æ –æ—Ç—Ü–∞ –∞ –≤–æ—Ç –ø–æ—Ç–æ–º—É —á—Ç–æ –ø–æ–ª –ü–æ–ª–∏–Ω–∞, –æ–Ω–∏, —É–Ω–∏—Å–µ–∫—Å, –æ–Ω–∞ –∏—Ö –Ω–æ—Å–∏–ª–∞, –º–Ω–µ —Ç–∞–∫ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å, —è —Ç–∞–∫–∞—è, –±–ª–∏–Ω, —á—Ç–æ —ç—Ç–æ, —è –ø—Ä–∏—à–ª–∞ –∫ –Ω–µ–π –¥–æ–º–æ–π, —Å—Ñ–æ—Ç–∫–∞–ª–∞, –∏ –≤—Å–µ, –∏ –º—ã –∏—Ö –∫—É–ø–∏–ª–∏, –µ—â–µ —Ç–æ–≥–¥–∞ —è —Å–º–æ—Ç—Ä–µ–ª–∞, —Ç–∏–ø–∞, –Ω–∞ –∑–æ–ª–æ—Ç–æ–º —è–±–ª–æ–∫–µ –æ–Ω–∏ —Å—Ç–æ–∏–ª–∏, —Ç–∏–ø–∞, –Ω—É, –¥–µ–≤—è—Ç–Ω–∞–¥—Ü–∞—Ç—å, –Ω—É, –≤–æ—Å–µ–º–Ω–∞–¥—Ü–∞—Ç—å, –Ω—É, –∫–∞–∫ –±—ã, –¥–∞,–î–∞,, –Ω—É, –Ω–∏—à–µ–≤–∞—è –ø–∞—Ä—Ñ—é–º–µ—Ä–∏—è, –∫–∞–∫ –±—ã, –ª–∞–¥–Ω–æ, –µ—â–µ –º–æ–∂–Ω–æ –∫–∞–∫ –±—ã —Å—Ö–∞–≤–∞—Ç—å, –Ω–æ —Å–æ—Ä–æ–∫ –ø—è—Ç—å, –±–ª—è–¥—å.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import WhisperForConditionalGeneration, WhisperProcessor, pipeline\n",
    "\n",
    "# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ ===\n",
    "device = \"cpu\"\n",
    "torch_dtype = torch.float32  # CPU –æ–±—ã—á–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Å float32\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps\"  # Apple GPU\n",
    "    setattr(torch.distributed, \"is_initialized\", lambda: False)  # monkey patch\n",
    "\n",
    "device = torch.device(device)\n",
    "\n",
    "# === –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –∏ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä ===\n",
    "model_id = \"antony66/whisper-large-v3-russian\"\n",
    "\n",
    "print(\"‚è≥ –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Whisper Large V3 Russian...\")\n",
    "whisper = WhisperForConditionalGeneration.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_safetensors=True,\n",
    ")\n",
    "\n",
    "processor = WhisperProcessor.from_pretrained(model_id)\n",
    "\n",
    "# === –°–æ–∑–¥–∞—ë–º –ø–∞–π–ø–ª–∞–π–Ω ASR ===\n",
    "asr_pipeline = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=whisper,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=256,\n",
    "    chunk_length_s=30,       # –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫—É—Å–∫–∞–º–∏ –ø–æ 30 —Å–µ–∫\n",
    "    batch_size=16,\n",
    "    return_timestamps=True,  # –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# === –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É ===\n",
    "audio_path = \"/home/ppwwrr/project_25/voices/voice-2.wav\"\n",
    "\n",
    "# === –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º –∞—É–¥–∏–æ ===\n",
    "print(f\"üéß –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª: {audio_path}...\")\n",
    "asr = asr_pipeline(\n",
    "    audio_path,\n",
    "    generate_kwargs={\"language\": \"russian\", \"max_new_tokens\": 256},\n",
    "    return_timestamps=False  # –Ω–∞–º –Ω–µ –Ω—É–∂–Ω—ã —Ç–∞–π–º–∫–æ–¥—ã\n",
    ")\n",
    "\n",
    "# === –í—ã–≤–æ–¥–∏–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç ===\n",
    "print(\"\\n‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:\\n\")\n",
    "print(asr[\"text\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
