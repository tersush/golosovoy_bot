{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a84f9d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: torch==2.9.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torchaudio) (2.9.0)\n",
      "Requirement already satisfied: filelock in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch==2.9.0->torchaudio) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from sympy>=1.13.3->torch==2.9.0->torchaudio) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from jinja2->torch==2.9.0->torchaudio) (3.0.3)\n",
      "Downloading torchaudio-2.9.0-cp312-cp312-manylinux_2_28_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchaudio\n",
      "Successfully installed torchaudio-2.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f66bd65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchcodec\n",
      "  Downloading torchcodec-0.8.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
      "Downloading torchcodec-0.8.1-cp312-cp312-manylinux_2_28_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hInstalling collected packages: torchcodec\n",
      "Successfully installed torchcodec-0.8.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torchcodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f8d17c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Downloading accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from accelerate) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from accelerate) (25.0)\n",
      "Requirement already satisfied: psutil in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from accelerate) (7.1.0)\n",
      "Requirement already satisfied: pyyaml in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from accelerate) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from accelerate) (2.9.0)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from accelerate) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from accelerate) (0.6.2)\n",
      "Requirement already satisfied: filelock in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (2025.10.0)\n",
      "Requirement already satisfied: requests in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from huggingface_hub>=0.21.0->accelerate) (1.2.0)\n",
      "Requirement already satisfied: setuptools in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.5.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from requests->huggingface_hub>=0.21.0->accelerate) (2025.8.3)\n",
      "Downloading accelerate-1.11.0-py3-none-any.whl (375 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.8/375.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hInstalling collected packages: accelerate\n",
      "Successfully installed accelerate-1.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef91a55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/salute-developers/GigaAM.git\n",
      "  Cloning https://github.com/salute-developers/GigaAM.git to /tmp/pip-req-build-9x_z8r11\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/salute-developers/GigaAM.git /tmp/pip-req-build-9x_z8r11\n",
      "  Resolved https://github.com/salute-developers/GigaAM.git to commit 6a8b511f753670ed38af6529bb89bbdc2191ba6a\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting hydra-core<=1.3.2 (from gigaam==0.1.0)\n",
      "  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: numpy in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from gigaam==0.1.0) (2.3.3)\n",
      "Collecting omegaconf<=2.3.0 (from gigaam==0.1.0)\n",
      "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pydub<=0.25.1 (from gigaam==0.1.0)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting sentencepiece<=0.2.0 (from gigaam==0.1.0)\n",
      "  Downloading sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting torch<=2.5.1 (from gigaam==0.1.0)\n",
      "  Downloading torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchaudio<=2.5.1 (from gigaam==0.1.0)\n",
      "  Downloading torchaudio-2.5.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting onnx==1.17.0 (from gigaam==0.1.0)\n",
      "  Downloading onnx-1.17.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting onnxruntime==1.17.3 (from gigaam==0.1.0)\n",
      "  Downloading onnxruntime-1.17.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: tqdm in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from gigaam==0.1.0) (4.67.1)\n",
      "Collecting protobuf>=3.20.2 (from onnx==1.17.0->gigaam==0.1.0)\n",
      "  Downloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting coloredlogs (from onnxruntime==1.17.3->gigaam==0.1.0)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime==1.17.3->gigaam==0.1.0)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: packaging in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from onnxruntime==1.17.3->gigaam==0.1.0) (25.0)\n",
      "Requirement already satisfied: sympy in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from onnxruntime==1.17.3->gigaam==0.1.0) (1.14.0)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from hydra-core<=1.3.2->gigaam==0.1.0)\n",
      "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from omegaconf<=2.3.0->gigaam==0.1.0) (6.0.3)\n",
      "Requirement already satisfied: filelock in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch<=2.5.1->gigaam==0.1.0) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch<=2.5.1->gigaam==0.1.0) (4.15.0)\n",
      "Requirement already satisfied: networkx in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch<=2.5.1->gigaam==0.1.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch<=2.5.1->gigaam==0.1.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch<=2.5.1->gigaam==0.1.0) (2025.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<=2.5.1->gigaam==0.1.0)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<=2.5.1->gigaam==0.1.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<=2.5.1->gigaam==0.1.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<=2.5.1->gigaam==0.1.0)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<=2.5.1->gigaam==0.1.0)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<=2.5.1->gigaam==0.1.0)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<=2.5.1->gigaam==0.1.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<=2.5.1->gigaam==0.1.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<=2.5.1->gigaam==0.1.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch<=2.5.1->gigaam==0.1.0)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch<=2.5.1->gigaam==0.1.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<=2.5.1->gigaam==0.1.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch<=2.5.1->gigaam==0.1.0)\n",
      "  Downloading triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: setuptools in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch<=2.5.1->gigaam==0.1.0) (80.9.0)\n",
      "Collecting sympy (from onnxruntime==1.17.3->gigaam==0.1.0)\n",
      "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from sympy->onnxruntime==1.17.3->gigaam==0.1.0) (1.3.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.17.3->gigaam==0.1.0)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from jinja2->torch<=2.5.1->gigaam==0.1.0) (3.0.3)\n",
      "Downloading onnx-1.17.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnxruntime-1.17.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m510.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K   \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.9/906.4 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:12:32\u001b[0mm\n",
      "\u001b[?25h\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ppwwrr/jupyter_env/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "             ^^^^^^\n",
      "  File \"/home/ppwwrr/jupyter_env/lib/python3.12/site-packages/pip/_internal/cli/main.py\", line 79, in main\n",
      "    return command.main(cmd_args)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ppwwrr/jupyter_env/lib/python3.12/site-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
      "    with self.main_context():\n",
      "  File \"/usr/lib/python3.12/contextlib.py\", line 144, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/home/ppwwrr/jupyter_env/lib/python3.12/site-packages/pip/_internal/cli/command_context.py\", line 19, in main_context\n",
      "    with self._main_context:\n",
      "  File \"/usr/lib/python3.12/contextlib.py\", line 610, in __exit__\n",
      "    raise exc_details[1]\n",
      "  File \"/usr/lib/python3.12/contextlib.py\", line 595, in __exit__\n",
      "    if cb(*exc_details):\n",
      "       ^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/contextlib.py\", line 144, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/home/ppwwrr/jupyter_env/lib/python3.12/site-packages/pip/_internal/utils/temp_dir.py\", line 42, in global_tempdir_manager\n",
      "    with ExitStack() as stack:\n",
      "  File \"/usr/lib/python3.12/contextlib.py\", line 610, in __exit__\n",
      "    raise exc_details[1]\n",
      "  File \"/usr/lib/python3.12/contextlib.py\", line 595, in __exit__\n",
      "    if cb(*exc_details):\n",
      "       ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ppwwrr/jupyter_env/lib/python3.12/site-packages/pip/_internal/utils/temp_dir.py\", line 169, in __exit__\n",
      "    self.cleanup()\n",
      "  File \"/home/ppwwrr/jupyter_env/lib/python3.12/site-packages/pip/_internal/utils/temp_dir.py\", line 212, in cleanup\n",
      "    rmtree(self._path, ignore_errors=False)\n",
      "  File \"/home/ppwwrr/jupyter_env/lib/python3.12/site-packages/pip/_vendor/tenacity/__init__.py\", line 291, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ppwwrr/jupyter_env/lib/python3.12/site-packages/pip/_vendor/tenacity/__init__.py\", line 381, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ppwwrr/jupyter_env/lib/python3.12/site-packages/pip/_vendor/tenacity/__init__.py\", line 316, in iter\n",
      "    return fut.result()\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/concurrent/futures/_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"/home/ppwwrr/jupyter_env/lib/python3.12/site-packages/pip/_vendor/tenacity/__init__.py\", line 384, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/ppwwrr/jupyter_env/lib/python3.12/site-packages/pip/_internal/utils/misc.py\", line 144, in rmtree\n",
      "    shutil.rmtree(dir, onexc=handler)  # type: ignore\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/usr/lib/python3.12/shutil.py\", line 785, in rmtree\n",
      "    _rmtree_safe_fd(fd, path, onexc)\n",
      "  File \"/usr/lib/python3.12/shutil.py\", line 686, in _rmtree_safe_fd\n",
      "    _rmtree_safe_fd(dirfd, fullname, onexc)\n",
      "  File \"/usr/lib/python3.12/shutil.py\", line 686, in _rmtree_safe_fd\n",
      "    _rmtree_safe_fd(dirfd, fullname, onexc)\n",
      "  File \"/usr/lib/python3.12/shutil.py\", line 686, in _rmtree_safe_fd\n",
      "    _rmtree_safe_fd(dirfd, fullname, onexc)\n",
      "  [Previous line repeated 2 more times]\n",
      "  File \"/usr/lib/python3.12/shutil.py\", line 715, in _rmtree_safe_fd\n",
      "    os.unlink(entry.name, dir_fd=topfd)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "# If package is not installed\n",
    "! pip install git+https://github.com/salute-developers/GigaAM.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a206a2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gigaam\n",
      "  Downloading gigaam-0.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting hydra-core<=1.3.2 (from gigaam)\n",
      "  Using cached hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n",
      "Requirement already satisfied: numpy in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from gigaam) (2.3.3)\n",
      "Collecting omegaconf<=2.3.0 (from gigaam)\n",
      "  Using cached omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pydub<=0.25.1 (from gigaam)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting sentencepiece<=0.2.0 (from gigaam)\n",
      "  Using cached sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Collecting torch<=2.5.1 (from gigaam)\n",
      "  Using cached torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Collecting torchaudio<=2.5.1 (from gigaam)\n",
      "  Using cached torchaudio-2.5.1-cp312-cp312-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting onnx==1.17.0 (from gigaam)\n",
      "  Using cached onnx-1.17.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting onnxruntime==1.17.3 (from gigaam)\n",
      "  Using cached onnxruntime-1.17.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: tqdm in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from gigaam) (4.67.1)\n",
      "Collecting protobuf>=3.20.2 (from onnx==1.17.0->gigaam)\n",
      "  Using cached protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting coloredlogs (from onnxruntime==1.17.3->gigaam)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime==1.17.3->gigaam)\n",
      "  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: packaging in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from onnxruntime==1.17.3->gigaam) (25.0)\n",
      "Requirement already satisfied: sympy in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from onnxruntime==1.17.3->gigaam) (1.14.0)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from hydra-core<=1.3.2->gigaam)\n",
      "  Using cached antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from omegaconf<=2.3.0->gigaam) (6.0.3)\n",
      "Requirement already satisfied: filelock in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch<=2.5.1->gigaam) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch<=2.5.1->gigaam) (4.15.0)\n",
      "Requirement already satisfied: networkx in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch<=2.5.1->gigaam) (3.5)\n",
      "Requirement already satisfied: jinja2 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch<=2.5.1->gigaam) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch<=2.5.1->gigaam) (2025.10.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<=2.5.1->gigaam)\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<=2.5.1->gigaam)\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<=2.5.1->gigaam)\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<=2.5.1->gigaam)\n",
      "  Using cached nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<=2.5.1->gigaam)\n",
      "  Using cached nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<=2.5.1->gigaam)\n",
      "  Using cached nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<=2.5.1->gigaam)\n",
      "  Using cached nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<=2.5.1->gigaam)\n",
      "  Using cached nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<=2.5.1->gigaam)\n",
      "  Using cached nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch<=2.5.1->gigaam)\n",
      "  Using cached nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch<=2.5.1->gigaam)\n",
      "  Using cached nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<=2.5.1->gigaam)\n",
      "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting triton==3.1.0 (from torch<=2.5.1->gigaam)\n",
      "  Using cached triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: setuptools in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from torch<=2.5.1->gigaam) (80.9.0)\n",
      "Collecting sympy (from onnxruntime==1.17.3->gigaam)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from sympy->onnxruntime==1.17.3->gigaam) (1.3.0)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime==1.17.3->gigaam)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ppwwrr/jupyter_env/lib/python3.12/site-packages (from jinja2->torch<=2.5.1->gigaam) (3.0.3)\n",
      "Downloading gigaam-0.1.0-py3-none-any.whl (22 kB)\n",
      "Using cached onnx-1.17.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.0 MB)\n",
      "Using cached onnxruntime-1.17.3-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "Using cached hydra_core-1.3.2-py3-none-any.whl (154 kB)\n",
      "Using cached omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached sentencepiece-0.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "Downloading torch-2.5.1-cp312-cp312-manylinux1_x86_64.whl (906.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m906.4/906.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0mm00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m846.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:06\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:07\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0mm\n",
      "\u001b[?25hDownloading torchaudio-2.5.1-cp312-cp312-manylinux1_x86_64.whl (3.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading protobuf-6.33.0-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m323.2/323.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
      "  Building wheel for antlr4-python3-runtime (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144591 sha256=72fe1caa04c6add1ff272dc815daf099e478ba23910d37fdfc8f57d3968001fc\n",
      "  Stored in directory: /home/ppwwrr/.cache/pip/wheels/1f/be/48/13754633f1d08d1fbfc60d5e80ae1e5d7329500477685286cd\n",
      "Successfully built antlr4-python3-runtime\n",
      "Installing collected packages: sentencepiece, pydub, flatbuffers, antlr4-python3-runtime, triton, sympy, protobuf, omegaconf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, humanfriendly, onnx, nvidia-cusparse-cu12, nvidia-cudnn-cu12, hydra-core, coloredlogs, onnxruntime, nvidia-cusolver-cu12, torch, torchaudio, gigaam\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 3.5.0\n",
      "    Uninstalling triton-3.5.0:\n",
      "      Successfully uninstalled triton-3.5.0\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.14.0\n",
      "    Uninstalling sympy-1.14.0:\n",
      "      Successfully uninstalled sympy-1.14.0\n",
      "  Attempting uninstall: nvidia-nvtx-cu12\n",
      "    Found existing installation: nvidia-nvtx-cu12 12.8.90\n",
      "    Uninstalling nvidia-nvtx-cu12-12.8.90:\n",
      "      Successfully uninstalled nvidia-nvtx-cu12-12.8.90\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-nccl-cu12\n",
      "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
      "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
      "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
      "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
      "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
      "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
      "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
      "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.9.0\n",
      "    Uninstalling torch-2.9.0:\n",
      "      Successfully uninstalled torch-2.9.0\n",
      "  Attempting uninstall: torchaudio\n",
      "    Found existing installation: torchaudio 2.9.0\n",
      "    Uninstalling torchaudio-2.9.0:\n",
      "      Successfully uninstalled torchaudio-2.9.0\n",
      "Successfully installed antlr4-python3-runtime-4.9.3 coloredlogs-15.0.1 flatbuffers-25.9.23 gigaam-0.1.0 humanfriendly-10.0 hydra-core-1.3.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 omegaconf-2.3.0 onnx-1.17.0 onnxruntime-1.17.3 protobuf-6.33.0 pydub-0.25.1 sentencepiece-0.2.0 sympy-1.13.1 torch-2.5.1 torchaudio-2.5.1 triton-3.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gigaam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "914992fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement pyannote (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for pyannote\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pyannote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16edb6f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load_model() got an unexpected keyword argument 'fp32_encoder'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m warnings.simplefilter(action=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m, category=\u001b[38;5;167;01mFutureWarning\u001b[39;00m)\n\u001b[32m      8\u001b[39m warnings.simplefilter(action=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m, category=\u001b[38;5;167;01mUserWarning\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m model = \u001b[43mgigaam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mctc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# GigaAM-V2 CTC model\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfp32_encoder\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# to use fp16 encoder weights - GPU only\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_flash\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# disable flash attention - colab does not support it\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m a=model.transcribe_longform(\u001b[33m\"\u001b[39m\u001b[33m/home/ppwwrr/project_25/voices/voice-2.wav\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(a)\n",
      "\u001b[31mTypeError\u001b[39m: load_model() got an unexpected keyword argument 'fp32_encoder'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "from typing import Dict\n",
    "\n",
    "import gigaam\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=UserWarning)\n",
    "\n",
    "model = gigaam.load_model(\n",
    "    \"ctc\",  # GigaAM-V2 CTC model\n",
    "    fp32_encoder=True,  # to use fp16 encoder weights - GPU only\n",
    "    use_flash=False,  # disable flash attention - colab does not support it\n",
    ")\n",
    "a=model.transcribe_longform(\"/home/ppwwrr/project_25/voices/voice-2.wav\")\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ce2128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄 Загружаем модель и процессор...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type gigaam-rnnt to instantiate a model of type gigaam. This is not supported for all configurations of models and can yield errors.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Критическая ошибка при загрузке модели: Cannot copy out of meta tensor; no data! Please use torch.nn.Module.to_empty() instead of torch.nn.Module.to() when moving module from meta to a different device.\n",
      "Пожалуйста, убедитесь, что ваша версия `transformers` обновлена и поддерживает указанную модель.\n",
      "❌ Модель не была загружена. Невозможно продолжить.\n",
      "🎶 Загружаем аудио: /home/ppwwrr/project_25/voices/voice-2.wav\n",
      "🔊 Ресемплирование с 48000 Гц до 16000 Гц...\n",
      "🔹 Общая длина аудио: 51.97 сек. Всего чанков: 6\n",
      "🟢 Обрабатываю чанк 1/6 (0.00s - 10.00s)...\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'generate'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 86\u001b[39m\n\u001b[32m     82\u001b[39m inputs = {k: v.to(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs.items()}\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m# Генерация транскрипции\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     pred_ids = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m(**inputs)\n\u001b[32m     88\u001b[39m text = processor.batch_decode(pred_ids, group_tokens=\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[32m0\u001b[39m].strip()\n\u001b[32m     89\u001b[39m transcripts.append(text)\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'generate'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "import os\n",
    "\n",
    "# === Параметры ===\n",
    "audio_path = \"/home/ppwwrr/project_25/voices/voice-2.wav\"\n",
    "model_id = \"waveletdeboshir/gigaam-rnnt\"\n",
    "chunk_seconds = 10  # длина одного чанка в секундах\n",
    "device_name = \"cpu\"\n",
    "device = torch.device(device_name) # Используем torch.device для удобства\n",
    "\n",
    "# Инициализируем переменные вне блока try, чтобы избежать NameError\n",
    "processor = None\n",
    "model = None\n",
    "\n",
    "# Проверка наличия аудиофайла\n",
    "if not os.path.exists(audio_path):\n",
    "    print(f\"❌ Ошибка: Аудиофайл '{audio_path}' не найден. Пожалуйста, убедитесь, что файл существует.\")\n",
    "    exit()\n",
    "\n",
    "# === Загружаем процессор и модель ===\n",
    "print(\"🔄 Загружаем модель и процессор...\")\n",
    "try:\n",
    "    processor = AutoProcessor.from_pretrained(model_id, trust_remote_code=True)\n",
    "    model = AutoModel.from_pretrained(\n",
    "        model_id,\n",
    "        trust_remote_code=True,\n",
    "        dtype=torch.float32,\n",
    "        device_map=\"cpu\" # Загружаем модель сразу на CPU\n",
    "    )\n",
    "    model.eval()\n",
    "except Exception as e:\n",
    "    # Если загрузка не удалась, модель и процессор остаются None.\n",
    "    print(f\"❌ Критическая ошибка при загрузке модели: {e}\")\n",
    "    print(\"Пожалуйста, убедитесь, что ваша версия `transformers` обновлена и поддерживает указанную модель.\")\n",
    "    exit() # Завершаем выполнение, если не удалось загрузить модель\n",
    "\n",
    "# Дополнительная проверка на случай, если exit() игнорируется в интерактивной среде\n",
    "if model is None or processor is None:\n",
    "    print(\"❌ Модель не была загружена. Невозможно продолжить.\")\n",
    "    exit()\n",
    "\n",
    "# === Загружаем аудио ===\n",
    "print(f\"🎶 Загружаем аудио: {audio_path}\")\n",
    "try:\n",
    "    wav, sr = torchaudio.load(audio_path)\n",
    "except Exception as e:\n",
    "    print(f\"❌ Ошибка при загрузке аудио: {e}\")\n",
    "    exit()\n",
    "\n",
    "if sr != 16000:\n",
    "    print(f\"🔊 Ресемплирование с {sr} Гц до 16000 Гц...\")\n",
    "    resampler = torchaudio.transforms.Resample(sr, 16000)\n",
    "    wav = resampler(wav)\n",
    "    sr = 16000\n",
    "\n",
    "# Переводим в моно (если не моно)\n",
    "if wav.shape[0] > 1:\n",
    "    print(\"🎧 Конвертация в моно...\")\n",
    "    wav = wav.mean(dim=0, keepdim=True)\n",
    "\n",
    "# === Делим на чанки ===\n",
    "chunk_size = chunk_seconds * sr\n",
    "num_chunks = (wav.shape[1] + chunk_size - 1) // chunk_size\n",
    "print(f\"🔹 Общая длина аудио: {wav.shape[1] / sr:.2f} сек. Всего чанков: {num_chunks}\")\n",
    "\n",
    "transcripts = []\n",
    "\n",
    "for i in range(num_chunks):\n",
    "    start = i * chunk_size\n",
    "    end = min((i + 1) * chunk_size, wav.shape[1])\n",
    "    chunk = wav[:, start:end]\n",
    "\n",
    "    print(f\"🟢 Обрабатываю чанк {i+1}/{num_chunks} ({start/sr:.2f}s - {end/sr:.2f}s)...\")\n",
    "    \n",
    "    # Обработка чанка\n",
    "    # Используем chunk.squeeze(0) для преобразования (1, M) -> (M,)\n",
    "    inputs = processor(chunk.squeeze(0), sampling_rate=sr, return_tensors=\"pt\")\n",
    "    \n",
    "    # 💡 УЛУЧШЕНИЕ: Перемещаем входные тензоры на устройство (CPU в данном случае)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Генерация транскрипции\n",
    "        pred_ids = model.generate(**inputs)\n",
    "    \n",
    "    text = processor.batch_decode(pred_ids, group_tokens=False)[0].strip()\n",
    "    transcripts.append(text)\n",
    "\n",
    "# === Склеиваем и выводим результат ===\n",
    "full_text = \" \".join(transcripts)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"✅ Готово! Финальная транскрипция:\")\n",
    "print(full_text)\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
