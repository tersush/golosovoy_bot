{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9436a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Using `chunk_length_s` is very experimental with seq2seq models. The results will not necessarily be entirely accurate and will have caveats. More information: https://github.com/huggingface/transformers/pull/20104. Ignore this warning with pipeline(..., ignore_warning=True). To use Whisper for long-form transcription, use rather the model's `generate` method directly as the model relies on it's own chunking mechanism (cf. Whisper original paper, section 3.8. Long-form Transcription).\n",
      "Using custom `forced_decoder_ids` from the (generation) config. This is deprecated in favor of the `task` and `language` flags/config options.\n",
      "Transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English. This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`. See https://github.com/huggingface/transformers/pull/28687 for more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéß –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª: /home/ppwwrr/project_25/voices/voice-2.wav\n",
      "\n",
      "‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:\n",
      "\n",
      " –ü–æ—Ç–æ–º—É —á—Ç–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Ä–∞–∑ —è —Å–º–æ—Ç—Ä–µ–ª–∞, –∫–æ—Ä–æ—á–µ, —É –º–µ–Ω—è –≤–æ—Ç —ç—Ç–∏ –¥—É—Ö–∏ –ø–æ—è–≤–∏–ª–∏—Å—å, —á—Ç–æ–±—ã –Ω–µ —Å–æ–≤—Ä–∞—Ç—å, –≤ 10-–º –∏–ª–∏ –≤ 11-–º –∫–ª–∞—Å—Å–µ, –≤–æ—Ç —Ç–∏–ø–∞ –≤–æ—Ç –ª–∏–±–æ –∫–æ–Ω–µ—Ü 10-–≥–æ, –ª–∏–±–æ –Ω–∞—á–∞–ª–æ 11-–≥–æ, –Ω—É –∫–æ—Ä–æ—á–µ, –≤–æ—Ç –æ–Ω–∏ —É –º–µ–Ω—è –ø–æ—è–≤–∏–ª–∏—Å—å, –º–Ω–µ –º–∞–º–∞ –∑–∞–∫–∞–∑–∞–ª–∞, –ø–æ—Ç–æ–º—É —á—Ç–æ —ç—Ç–æ –¥—É—Ö–∏ –ü–æ–ª–∏–Ω–∏–Ω–æ–≥–æ –æ—Ç—Ü–∞, –≤–æ—Ç. –ü–æ—Ç–æ–º—É —á—Ç–æ –ü–æ–ª–∏–Ω–∞ –£–Ω–∏—Å–∞–∫—Å –û–Ω–∞ –∏—Ö –Ω–æ—Å–∏–ª–∞, –º–Ω–µ —Ç–∞–∫ –ø–æ–Ω—Ä–∞–≤–∏–ª–æ—Å—å, —è —Ç–∞–∫–∞—è, –±–ª–∏–Ω, —á—Ç–æ —ç—Ç–æ, —è –ø—Ä–∏—à–ª–∞ –∫ –Ω–µ–π –¥–æ–º–æ–π, —Å—Ñ–æ—Ç–∫–∞–ª–∞, –∏ –≤—Å–µ, –∏ –º—ã –∏—Ö –∫—É–ø–∏–ª–∏, –∏ –µ—â–µ —Ç–æ–≥–¥–∞ —è —Å–º–æ—Ç—Ä–µ–ª–∞, —Ç–∏–ø–∞, –Ω–∞ –∑–æ–ª–æ—Ç–æ–º —è–±–ª–æ–∫–µ –æ–Ω–∏ —Å—Ç–æ–∏–ª–∏, —Ç–∏–ø–∞, –Ω—É, 19, –Ω—É, 18, –Ω—É, –∫–∞–∫ –∫–∞–∫ –±—ã, –¥–∞, –¥–æ—Ä–æ–≥–æ –ù—É, –Ω–∏—à–µ–≤–∞—è –ø–∞—Ä—Ñ—é–º–µ—Ä–∏—è –ö–∞–∫ –±—ã, –ª–∞–¥–Ω–æ –ï—â—ë –º–æ–∂–Ω–æ –∫–∞–∫ –±—ã —Å—Ö–∞–≤–∞—Ç—å –ù–æ —Å–æ—Ä–æ–∫ –ø—è—Ç—å, –±–ª—è–¥—å\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "# === –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞ ===\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "# === –ú–æ–¥–µ–ª—å ===\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch_dtype,\n",
    "    low_cpu_mem_usage=True,\n",
    "    use_safetensors=True\n",
    ").to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "# === –°–æ–∑–¥–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω ===\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# === –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É ===\n",
    "audio_path = \"/home/ppwwrr/project_25/voices/voice-2.wav\"\n",
    "\n",
    "# === –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º ===\n",
    "print(f\"üéß –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª: {audio_path}\")\n",
    "\n",
    "# `return_timestamps=True` –∞–∫—Ç–∏–≤–∏—Ä—É–µ—Ç long-form —Ä–µ–∂–∏–º\n",
    "result = pipe(\n",
    "    audio_path,\n",
    "    return_timestamps=True,      # ‚úÖ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–ª—è –¥–ª–∏–Ω–Ω—ã—Ö –∞—É–¥–∏–æ\n",
    "    chunk_length_s=30,           # –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –∫—É—Å–∫–∞–º–∏ –ø–æ 30 —Å–µ–∫—É–Ω–¥\n",
    "    stride_length_s=(5, 5)       # –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ –º–µ–∂–¥—É —á–∞–Ω–∫–∞–º–∏ (–¥–ª—è —Ç–æ—á–Ω–æ—Å—Ç–∏)\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞:\\n\")\n",
    "print(result[\"text\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
